{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a739eb8b-584c-42ab-85e8-08610f04a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0724fc1f-4ea5-40d3-8d4c-558de34973a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d57e89-98ae-472b-85ff-eeb145b68fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766b2056-9fb9-401f-a461-b8c2e822b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e0e103-64d3-43d0-be84-24f9ed89d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d11fca-1fa7-4be8-bf10-2b6cab76dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb171087-37ea-47e2-b2dd-d7d90e22ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7a0801-e575-44a3-9165-6799af125b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3425, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7be1654c-5642-4619-997b-4ee600f7cacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([64, 27]), torch.Size([27]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape, W2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d722e07-545a-49bf-a017-026c488cc418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_prob        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "prob            | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "count_sum_inv   | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dlogits         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] =  -1.0/n\n",
    "dlogprob_to_dprob = 1.0 / probs\n",
    "dprobs = (dlogprob_to_dprob) * dlogprobs\n",
    "dprob_to_dcount_sum_inv = counts\n",
    "dcount_sum_inv = (dprob_to_dcount_sum_inv * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcntsuminv_to_dcntsum = -(1 / counts_sum **2)\n",
    "dcounts_sum = dcntsuminv_to_dcntsum * dcount_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogits_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "temp_tensor = torch.zeros_like(logits)\n",
    "indices = logits.max(1, keepdim=True).indices.view(-1)\n",
    "temp_tensor[range(n), indices] = 1\n",
    "dlogits += temp_tensor * dlogits_maxes\n",
    "\n",
    "# in matrix multiplication we are using the same scalar from the other matrix, so when backprob, we just accumulate the gradiate column wise\n",
    "cmp('log_prob', dlogprobs, logprobs)\n",
    "cmp('prob', dprobs, probs)\n",
    "cmp('count_sum_inv', dcount_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('dlogits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf900093-d5fe-4b46-a7eb-0dd0d5843b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x73c731f66e30>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(temp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31c6426b-6e3c-4429-b771-9b0938f1feed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 19, 14,  0, 17, 14,  5, 20, 24,  2, 26,  8,  3,  2, 16, 23, 14, 16,\n",
       "        15,  2, 24,  5, 17,  0,  6, 10, 11,  5, 12, 21, 20, 18])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
